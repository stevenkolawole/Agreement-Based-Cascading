model,accuracy,cost,avg_latency
Meta-Llama-3.1-8B-Instruct-Turbo,0.78,0.0136188,1.0289650964736938
Meta-Llama-3.1-70B-Instruct-Turbo,0.96,0.06450576,2.5431721925735475
Meta-Llama-3.1-405B-Instruct-Turbo,0.96,0.3693899999999999,2.0683387660980226
Meta-Llama-3-8B-Instruct-Turbo,0.7,0.013075379999999994,0.7859009885787964
Meta-Llama-3-70B-Instruct-Turbo,0.92,0.06310479999999999,1.5949582433700562
Meta-Llama-3-8B-Instruct-Lite,0.62,0.007631,1.9481379413604736
Meta-Llama-3-70B-Instruct-Lite,0.86,0.03887244000000001,4.966560225486756
Llama-3-8b-chat-hf,0.68,0.014524200000000003,0.7067459630966186
Llama-3-70b-chat-hf,0.86,0.0644661,1.0102180910110474
gemma-2-27b-it,0.82,0.06467839999999997,2.7134318208694457
gemma-2-9b-it,0.74,0.024163199999999985,1.5680730390548705
dbrx-instruct,0.7,0.014377999999999995,2.0800977182388305
deepseek-llm-67b-chat,0.76,0.07315919999999998,4.874005279541016
gemma-2b-it,0.0,0.007865799999999997,1.137247085571289
MythoMax-L2-13b,0.0,0.017695,1.7238367366790772
Llama-2-13b-chat-hf,0.16,0.033030300000000005,8.150947093963623
Mistral-7B-Instruct-v0.1,0.14,0.017508200000000005,2.576721019744873
Mistral-7B-Instruct-v0.2,0.3,0.018976600000000003,2.225579409599304
Mistral-7B-Instruct-v0.3,0.3,0.017580400000000006,1.5491976499557496
Qwen1.5-72B-Chat,0.8,0.0720117,2.2615559768676756
Qwen1.5-110B-Chat,0.86,0.14489280000000004,2.646498498916626
StripedHyena-Nous-7B,0.0,0.0172002,1.6423168659210206
