model,accuracy,cost,avg_latency
Llama-3.2-3B-Instruct-Turbo,0.8,0.00023946,2.5806227684020997
Meta-Llama-3.1-8B-Instruct-Turbo,0.8,0.0006784199999999999,3.670637607574463
Mistral-7B-Instruct-v0.3,0.4,0.0009038000000000001,2.990202760696411
Qwen2-72B-Instruct,0.8,0.0037935,7.4482344627380375
WizardLM-2-8x22B,0.8,0.0009324,3.0688474655151365
Meta-Llama-3.1-70B-Instruct-Turbo,0.8,0.00333168,6.51715874671936
Meta-Llama-3.1-405B-Instruct-Turbo,1.0,0.018775,3.7262817859649657
MoT-LLM Cascade 2-level,1.0,0.00631052,23.474041604995726
CoE 2-level,1.0,0.00146872,20.085112237930296
AutoMix_T 2-level,0.8,0.006812899999999999,17.39045433998108
AutoMix_P 2-level,0.8,0.0059086,9.325855922698974
