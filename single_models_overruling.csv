model,accuracy,cost,avg_latency
Meta-Llama-3.1-8B-Instruct-Turbo,0.88,0.006127559999999999,1.0728195667266847
Meta-Llama-3.1-70B-Instruct-Turbo,0.92,0.02115608,0.6382067012786865
Meta-Llama-3.1-405B-Instruct-Turbo,0.96,0.12023500000000004,0.6322822952270508
Meta-Llama-3-8B-Instruct-Turbo,0.92,0.006169319999999999,1.0372341966629028
Meta-Llama-3-70B-Instruct-Turbo,0.96,0.02270312,1.0360121202468873
Meta-Llama-3-8B-Instruct-Lite,0.82,0.0036088000000000005,2.5129806661605834
Meta-Llama-3-70B-Instruct-Lite,0.94,0.015198840000000002,4.673916296958923
Llama-3-8b-chat-hf,0.82,0.0060842,0.7518620347976684
Llama-3-70b-chat-hf,0.96,0.0226287,0.6619306039810181
Llama-2-13b-chat-hf,0.6,0.013338899999999997,3.4382421255111693
gemma-2-27b-it,0.98,0.0190864,0.4897184944152832
gemma-2-9b-it,0.92,0.007160399999999999,0.4804037809371948
deepseek-llm-67b-chat,0.94,0.020594699999999997,0.4697080039978027
gemma-2b-it,0.6,0.0023618000000000003,0.27072843551635745
Mistral-7B-Instruct-v0.1,0.76,0.005473400000000001,0.4110617351531982
Mistral-7B-Instruct-v0.2,0.88,0.0060739999999999995,0.6312702417373657
Mistral-7B-Instruct-v0.3,0.86,0.005494999999999999,0.3869930410385132
Qwen1.5-72B-Chat,0.94,0.021427199999999997,0.3615664720535278
Qwen1.5-110B-Chat,0.64,0.0427788,0.3822439670562744
StripedHyena-Nous-7B,0.9,0.0053934,0.32685269832611086
