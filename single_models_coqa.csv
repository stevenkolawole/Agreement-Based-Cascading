model,accuracy,cost,avg_latency
Meta-Llama-3.1-8B-Instruct-Turbo,0.06,0.009597419999999999,0.6391241312026977
Meta-Llama-3.1-70B-Instruct-Turbo,0.44,0.043753600000000004,0.7041080093383789
Meta-Llama-3.1-405B-Instruct-Turbo,0.4,0.24896999999999994,0.9504275178909302
Meta-Llama-3-8B-Instruct-Turbo,0.32,0.008774279999999997,0.4385959434509277
Meta-Llama-3-70B-Instruct-Turbo,0.52,0.042871839999999994,0.7054391002655029
Meta-Llama-3-8B-Instruct-Lite,0.3,0.004891899999999999,0.4605064344406128
Meta-Llama-3-70B-Instruct-Lite,0.48,0.02631474000000001,1.5989338302612304
Llama-3-8b-chat-hf,0.24,0.009744000000000003,0.5905927038192749
Llama-3-70b-chat-hf,0.56,0.043803900000000014,0.46603675365448
Llama-2-13b-chat-hf,0.16,0.017438400000000003,1.3363702249526979
gemma-2-27b-it,0.06,0.03949360000000002,0.4525315475463867
gemma-2-9b-it,0.02,0.014829,1.652769923210144
deepseek-llm-67b-chat,0.32,0.04515479999999999,1.097037491798401
gemma-2b-it,0.3,0.0049339,0.3742549133300781
Mistral-7B-Instruct-v0.1,0.26,0.0109152,0.5391627502441406
Mistral-7B-Instruct-v0.2,0.02,0.011142999999999997,0.44072779178619387
Mistral-7B-Instruct-v0.3,0.28,0.010990999999999999,0.39244848251342773
Qwen1.5-72B-Chat,0.02,0.0440271,0.43841387748718263
Qwen1.5-110B-Chat,0.02,0.0882018,0.46101113319396975
StripedHyena-Nous-7B,0.28,0.0108846,0.41016839027404783
