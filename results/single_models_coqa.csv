model,accuracy,cost,avg_latency
Meta-Llama-3-8B-Instruct-Lite,0.41802321241976415,0.08815389999999988,0.6478066039085388
Meta-Llama-3.1-8B-Instruct-Turbo,0.43653071954333783,0.16049862000000006,1.728480248451233
gemma-2-9b-it,0.14323179612275042,0.2672757,0.4269642472267151
Qwen2-72B-Instruct,0.4449672513249215,0.800028899999999,0.5047368574142456
gemma-2-27b-it,0.5427801070515197,0.7158096,0.7657218532562255
Meta-Llama-3.1-70B-Instruct-Turbo,0.5117188063794472,0.7841424799999999,0.7971073536872864
Meta-Llama-3.1-405B-Instruct-Turbo,0.46553375438596484,4.454935000000001,4.504371177196503
MoT-LLM Cascade 2-level,0.4527646534892912,0.7630451199999995,0.865362545967102
CoE 2-level,0.5120090110009465,0.3057454399999999,1.1230859360694885
AutoMix_T 2-level,0.5026521496370743,1.256804460000001,9.705503777503967
AutoMix_P 2-level,0.51578580220362866,1.2317936200000013,6.867755172252655
FrugalGPT 2-level,0.4974695523911825,0.6542112999999998,0.9863808646202087
MoT-LLM Cascade 3-level,0.4729375037885675,0.9287962999999994,0.8899325380325317
CoE 3-level,0.5206724982939388,0.9886399999999999,3.187626477718353
AutoMix_T 3-level,0.5163910934744268,2.0439185000000006,14.322043043136597
AutoMix_P 3-level,0.5207257796902561,1.9400640200000001,13.237927858829499
FrugalGPT 3-level,0.50241734417344173,3.4973090599999965,6.56690254688263
